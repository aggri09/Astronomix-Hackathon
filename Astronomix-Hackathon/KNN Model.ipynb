{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da60bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69c9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('exoPlanets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93.85  83.81  20.1  ...  61.42   5.08 -39.54]\n",
      " [-38.88 -33.83 -58.54 ...   6.46  16.    19.93]\n",
      " [532.64 535.92 513.73 ... -28.91 -70.02 -96.67]\n",
      " ...\n",
      " [273.39 278.   261.73 ...  88.42  79.07  79.43]\n",
      " [  3.82   2.09  -3.29 ... -14.55  -6.41  -2.55]\n",
      " [323.28 306.36 293.16 ... -16.72 -14.09  27.82]]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[: , 1:].values\n",
    "Y = dataset.iloc[: , 0].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c3c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.    93.85  83.81 ...  39.32  61.42   5.08]\n",
      " [  2.   -38.88 -33.83 ... -11.7    6.46  16.  ]\n",
      " [  2.   532.64 535.92 ... -11.8  -28.91 -70.02]\n",
      " ...\n",
      " [  1.   273.39 278.   ...  65.73  88.42  79.07]\n",
      " [  1.     3.82   2.09 ...  -4.65 -14.55  -6.41]\n",
      " [  1.   323.28 306.36 ... -41.31 -16.72 -14.09]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan , strategy='mean')\n",
    "imputer.fit(X[: , 1:])\n",
    "X[: , 1:]= imputer.transform(X[: , 1:])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "845cf998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with True for NaN values:\n",
      "      LABEL  FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  \\\n",
      "0     False   False   False   False   False   False   False   False   False   \n",
      "1     False   False   False   False   False   False   False   False   False   \n",
      "2     False   False   False   False   False   False   False   False   False   \n",
      "3     False   False   False   False   False   False   False   False   False   \n",
      "4     False   False   False   False   False   False   False   False   False   \n",
      "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "5082  False   False   False   False   False   False   False   False   False   \n",
      "5083  False   False   False   False   False   False   False   False   False   \n",
      "5084  False   False   False   False   False   False   False   False   False   \n",
      "5085  False   False   False   False   False   False   False   False   False   \n",
      "5086  False   False   False   False   False   False   False   False   False   \n",
      "\n",
      "      FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  FLUX.3192  \\\n",
      "0      False  ...      False      False      False      False      False   \n",
      "1      False  ...      False      False      False      False      False   \n",
      "2      False  ...      False      False      False      False      False   \n",
      "3      False  ...      False      False      False      False      False   \n",
      "4      False  ...      False      False      False      False      False   \n",
      "...      ...  ...        ...        ...        ...        ...        ...   \n",
      "5082   False  ...      False      False      False      False      False   \n",
      "5083   False  ...      False      False      False      False      False   \n",
      "5084   False  ...      False      False      False      False      False   \n",
      "5085   False  ...      False      False      False      False      False   \n",
      "5086   False  ...      False      False      False      False      False   \n",
      "\n",
      "      FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "0         False      False      False      False      False  \n",
      "1         False      False      False      False      False  \n",
      "2         False      False      False      False      False  \n",
      "3         False      False      False      False      False  \n",
      "4         False      False      False      False      False  \n",
      "...         ...        ...        ...        ...        ...  \n",
      "5082      False      False      False      False      False  \n",
      "5083      False      False      False      False      False  \n",
      "5084      False      False      False      False      False  \n",
      "5085      False      False      False      False      False  \n",
      "5086      False      False      False      False      False  \n",
      "\n",
      "[5087 rows x 3198 columns]\n"
     ]
    }
   ],
   "source": [
    "nan_values = dataset.isna()  # Returns a DataFrame with True for NaN values\n",
    "nan_values_count = dataset.isna().sum()  # Returns the count of NaN values in each column\n",
    "\n",
    "# Display the DataFrame with True for NaN values\n",
    "print(\"DataFrame with True for NaN values:\")\n",
    "print(nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "285145c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.4000e-01  2.3200e+00  6.8000e-01 ...  1.8760e+01  1.0610e+01\n",
      "   4.8400e+00]\n",
      " [-7.1000e-01 -5.7400e+00  6.9100e+00 ...  2.2170e+01  2.8280e+01\n",
      "   3.3190e+01]\n",
      " [ 3.5743e+02  3.1859e+02  3.1365e+02 ...  8.7860e+01  7.4920e+01\n",
      "   4.2620e+01]\n",
      " ...\n",
      " [ 2.7360e+01  3.8730e+01  3.5090e+01 ...  3.5492e+02  3.0440e+02\n",
      "   2.4711e+02]\n",
      " [ 1.1210e+01  1.7100e+00  1.3350e+01 ... -1.9000e-01 -1.3580e+01\n",
      "  -1.0570e+01]\n",
      " [ 1.0230e+01  3.0000e-01 -2.5800e+00 ... -4.8480e+01 -3.4420e+01\n",
      "  -4.3840e+01]]\n",
      "[[-422.24 -425.42 -413.99 ... -497.91 -468.84 -407.23]\n",
      " [   5.8     4.49   -0.84 ...    3.3    -2.42    2.42]\n",
      " [  21.65   20.3    10.92 ...   10.91   15.32    7.79]\n",
      " ...\n",
      " [  23.78   17.54   10.82 ...   23.6    -2.52    5.4 ]\n",
      " [ -13.16   -9.75    8.05 ...  -10.66  -34.89   -1.86]\n",
      " [ -46.88 -104.24  -34.9  ...   16.29  -21.13   13.92]]\n",
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y, test_size=0.2,random_state=0)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(Y_train)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c838d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[: , 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[: , 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load a dataset (e.g., the Iris dataset for demonstration)\n",
    "iris = pd.read_csv('exoPlanets.csv')\n",
    "X = iris.iloc[: , 1:].values\n",
    "y = iris.iloc[: , 0].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier (SVC for classification)\n",
    "model = SVC(kernel='linear', C=1.0)  # You can choose different kernels (linear, rbf, etc.) and C values\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print a classification report for more detailed evaluation metrics\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72da697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93.85  83.81  20.1  ...  61.42   5.08 -39.54]\n",
      " [-38.88 -33.83 -58.54 ...   6.46  16.    19.93]\n",
      " [532.64 535.92 513.73 ... -28.91 -70.02 -96.67]\n",
      " ...\n",
      " [273.39 278.   261.73 ...  88.42  79.07  79.43]\n",
      " [  3.82   2.09  -3.29 ... -14.55  -6.41  -2.55]\n",
      " [323.28 306.36 293.16 ... -16.72 -14.09  27.82]]\n",
      "        Feature  Importance\n",
      "3196  FLUX.3197         0.0\n",
      "819    FLUX.820         0.0\n",
      "1960  FLUX.1961         0.0\n",
      "1963  FLUX.1964         0.0\n",
      "816    FLUX.817         0.0\n",
      "815    FLUX.816         0.0\n",
      "1964  FLUX.1965         0.0\n",
      "820    FLUX.821         0.0\n",
      "812    FLUX.813         0.0\n",
      "810    FLUX.811         0.0\n",
      "      LABEL   FLUX.1   FLUX.5   FLUX.6   FLUX.8  FLUX.9  FLUX.10  FLUX.13  \\\n",
      "0         2    93.85   -39.56  -124.71   -96.27  -79.89  -160.17  -173.71   \n",
      "1         2   -38.88   -79.31   -72.81   -85.33  -83.97   -73.38   -73.15   \n",
      "2         2   532.64   456.45   466.00   486.39  436.56   484.39   492.23   \n",
      "3         2   326.52   317.74   312.70   311.31  312.42   323.33   313.11   \n",
      "4         2 -1107.21 -1057.55 -1034.48 -1022.71 -989.57  -970.88  -888.66   \n",
      "...     ...      ...      ...      ...      ...     ...      ...      ...   \n",
      "5082      1   -91.91   -68.00   -68.24   -49.25  -30.92   -11.88    16.85   \n",
      "5083      1   989.75   755.11   615.78   458.87  492.84   384.34   208.06   \n",
      "5084      1   273.39   280.73   264.90   254.88  237.60   238.51   177.53   \n",
      "5085      1     3.82     1.66    -0.75    -0.03    3.28     6.29    -2.24   \n",
      "5086      1   323.28   249.89   218.30   178.93  118.93   130.68    72.07   \n",
      "\n",
      "      FLUX.14  FLUX.16  ...  FLUX.3176  FLUX.3178  FLUX.3180  FLUX.3181  \\\n",
      "0     -146.56  -102.85  ...     131.90    -193.16     -17.56     -17.31   \n",
      "1      -86.13   -61.27  ...      -9.80     -19.53     -23.88     -33.07   \n",
      "2      441.20   481.28  ...      -6.53      14.00     -34.98     -32.08   \n",
      "3      313.89   330.92  ...     -27.71     -36.12       6.63      10.66   \n",
      "4     -853.95  -754.48  ...    -539.29    -672.71    -597.60    -560.77   \n",
      "...       ...      ...  ...        ...        ...        ...        ...   \n",
      "5082    26.54    36.93  ...     -56.14     -26.43      -2.19      24.14   \n",
      "5083   224.73    53.22  ...      51.73      -1.19      83.97      59.61   \n",
      "5084   211.27   226.61  ...      48.44      37.64      61.58      18.71   \n",
      "5085    -3.27    -4.22  ...     -12.70      -8.66      -8.58      -3.63   \n",
      "5086   198.89   208.08  ...     -26.11     -26.63      24.86      42.61   \n",
      "\n",
      "      FLUX.3185  FLUX.3187  FLUX.3188  FLUX.3189  FLUX.3191  FLUX.3194  \n",
      "0         -9.60     -16.51     -78.07    -102.15      25.13      39.32  \n",
      "1        -12.66      12.53      -3.28     -32.21     -24.89     -11.70  \n",
      "2        -70.77     -83.83     -71.69      13.31     -29.89     -11.80  \n",
      "3        -25.80       7.42       5.71      -3.73      30.05      -8.77  \n",
      "4       -513.24    -521.95    -594.37    -401.66    -357.24    -399.71  \n",
      "...         ...        ...        ...        ...        ...        ...  \n",
      "5082      61.37     103.68     139.95     147.26     155.64     -24.45  \n",
      "5083     103.98      36.64     -26.50      -4.84     -37.84      38.03  \n",
      "5084       7.96     -23.42     -26.82     -53.89      30.99      65.73  \n",
      "5085     -12.21      -5.05      10.86      -3.23      -4.61      -4.65  \n",
      "5086      23.18      13.89      71.19       0.97      -1.63     -41.31  \n",
      "\n",
      "[5087 rows x 2137 columns]\n",
      "Number of columns in the dataset: 2137\n",
      "[[ 93.85  83.81  20.1  ...  61.42   5.08 -39.54]\n",
      " [-38.88 -33.83 -58.54 ...   6.46  16.    19.93]\n",
      " [532.64 535.92 513.73 ... -28.91 -70.02 -96.67]\n",
      " ...\n",
      " [273.39 278.   261.73 ...  88.42  79.07  79.43]\n",
      " [  3.82   2.09  -3.29 ... -14.55  -6.41  -2.55]\n",
      " [323.28 306.36 293.16 ... -16.72 -14.09  27.82]]\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "df=pd.read_csv('exoPlanets.csv')\n",
    "df.describe()\n",
    "X = df.iloc[: , 1:].values\n",
    "Y = df.iloc[: , 0].values\n",
    "print(X)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan , strategy='mean')\n",
    "imputer.fit(X[: , 1:])\n",
    "X[: , 1:]= imputer.transform(X[: , 1:])\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to your data\n",
    "clf.fit(X, Y)  # X is your feature matrix, y is your target labels\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "# Assuming you have a DataFrame 'df' with feature names\n",
    "feature_importance_df = pd.DataFrame({'Feature': df.columns[1:], 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Print or visualize the top N important features (you can change N as needed)\n",
    "N = 10  # Adjust this based on how many top features you want to see\n",
    "top_features = feature_importance_df.head(N)\n",
    "print(top_features)\n",
    "# Find features with 0 importance\n",
    "zero_importance_features = feature_importance_df[feature_importance_df['Importance'] == 0]['Feature']\n",
    "\n",
    "# Remove features with 0 importance from your DataFrame 'df'\n",
    "df_filtered = df.drop(columns=zero_importance_features)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df_filtered)\n",
    "# Assuming your DataFrame is named 'df'\n",
    "num_columns = df_filtered.shape[1]\n",
    "print(\"Number of columns in the dataset:\", num_columns)\n",
    "X_filtered = df_filtered.iloc[: , 1:].values\n",
    "print(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_filtered_train, X_filtered_test, Y_train, Y_test = train_test_split(X_filtered, Y, test_size=0.3, random_state=0)\n",
    "# Step 4: Create a KNN classifier and set hyperparameters to tune\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Values of k to be tuned\n",
    "    'weights': ['uniform', 'distance'],  # Weighting strategy\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "# Step 5: Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_filtered_train, Y_train)\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "# Step 6: Create a KNN classifier with the best hyperparameters\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "# Step 7: Train the classifier on the training data\n",
    "best_knn.fit(X_filtered_train, Y_train)\n",
    "# Step 8: Make predictions on the testing data\n",
    "Y_pred = best_knn.predict(X_filtered_test)\n",
    "# Step 9: Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32307bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
