Results Of Models-
1)KNN Model

[[ 93.85  83.81  20.1  ...  61.42   5.08 -39.54]
 [-38.88 -33.83 -58.54 ...   6.46  16.    19.93]
 [532.64 535.92 513.73 ... -28.91 -70.02 -96.67]
 ...
 [273.39 278.   261.73 ...  88.42  79.07  79.43]
 [  3.82   2.09  -3.29 ... -14.55  -6.41  -2.55]
 [323.28 306.36 293.16 ... -16.72 -14.09  27.82]]
        Feature  Importance
3196  FLUX.3197         0.0
819    FLUX.820         0.0
1960  FLUX.1961         0.0
1963  FLUX.1964         0.0
816    FLUX.817         0.0
815    FLUX.816         0.0
1964  FLUX.1965         0.0
820    FLUX.821         0.0
812    FLUX.813         0.0
810    FLUX.811         0.0
      LABEL   FLUX.1   FLUX.5   FLUX.6   FLUX.8  FLUX.9  FLUX.10  FLUX.13  \
0         2    93.85   -39.56  -124.71   -96.27  -79.89  -160.17  -173.71   
1         2   -38.88   -79.31   -72.81   -85.33  -83.97   -73.38   -73.15   
2         2   532.64   456.45   466.00   486.39  436.56   484.39   492.23   
3         2   326.52   317.74   312.70   311.31  312.42   323.33   313.11   
4         2 -1107.21 -1057.55 -1034.48 -1022.71 -989.57  -970.88  -888.66   
...     ...      ...      ...      ...      ...     ...      ...      ...   
5082      1   -91.91   -68.00   -68.24   -49.25  -30.92   -11.88    16.85   
5083      1   989.75   755.11   615.78   458.87  492.84   384.34   208.06   
5084      1   273.39   280.73   264.90   254.88  237.60   238.51   177.53   
5085      1     3.82     1.66    -0.75    -0.03    3.28     6.29    -2.24   
5086      1   323.28   249.89   218.30   178.93  118.93   130.68    72.07   

      FLUX.14  FLUX.16  ...  FLUX.3176  FLUX.3178  FLUX.3180  FLUX.3181  \
0     -146.56  -102.85  ...     131.90    -193.16     -17.56     -17.31   
1      -86.13   -61.27  ...      -9.80     -19.53     -23.88     -33.07   
2      441.20   481.28  ...      -6.53      14.00     -34.98     -32.08   
3      313.89   330.92  ...     -27.71     -36.12       6.63      10.66   
4     -853.95  -754.48  ...    -539.29    -672.71    -597.60    -560.77   
...       ...      ...  ...        ...        ...        ...        ...   
5082    26.54    36.93  ...     -56.14     -26.43      -2.19      24.14   
5083   224.73    53.22  ...      51.73      -1.19      83.97      59.61   
5084   211.27   226.61  ...      48.44      37.64      61.58      18.71   
5085    -3.27    -4.22  ...     -12.70      -8.66      -8.58      -3.63   
5086   198.89   208.08  ...     -26.11     -26.63      24.86      42.61   

      FLUX.3185  FLUX.3187  FLUX.3188  FLUX.3189  FLUX.3191  FLUX.3194  
0         -9.60     -16.51     -78.07    -102.15      25.13      39.32  
1        -12.66      12.53      -3.28     -32.21     -24.89     -11.70  
2        -70.77     -83.83     -71.69      13.31     -29.89     -11.80  
3        -25.80       7.42       5.71      -3.73      30.05      -8.77  
4       -513.24    -521.95    -594.37    -401.66    -357.24    -399.71  
...         ...        ...        ...        ...        ...        ...  
5082      61.37     103.68     139.95     147.26     155.64     -24.45  
5083     103.98      36.64     -26.50      -4.84     -37.84      38.03  
5084       7.96     -23.42     -26.82     -53.89      30.99      65.73  
5085     -12.21      -5.05      10.86      -3.23      -4.61      -4.65  
5086      23.18      13.89      71.19       0.97      -1.63     -41.31  

[5087 rows x 2137 columns]
Number of columns in the dataset: 2137
[[ 93.85  83.81  20.1  ...  61.42   5.08 -39.54]
 [-38.88 -33.83 -58.54 ...   6.46  16.    19.93]
 [532.64 535.92 513.73 ... -28.91 -70.02 -96.67]
 ...
 [273.39 278.   261.73 ...  88.42  79.07  79.43]
 [  3.82   2.09  -3.29 ... -14.55  -6.41  -2.55]
 [323.28 306.36 293.16 ... -16.72 -14.09  27.82]]
Best Hyperparameters: {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}
Accuracy: 0.99


2)Decision Tree 

Accuracy: 0.9783889980353635
Classification Report:
              precision    recall  f1-score   support

           1       0.99      0.99      0.99      1010
           2       0.06      0.12      0.08         8

    accuracy                           0.98      1018
   macro avg       0.53      0.56      0.54      1018
weighted avg       0.99      0.98      0.98      1018


3) SVM Model

Accuracy: 0.9616895874263262
Classification Report:
              precision    recall  f1-score   support

           1       0.99      0.97      0.98      1010
           2       0.03      0.12      0.05         8

    accuracy                           0.96      1018
   macro avg       0.51      0.55      0.51      1018
weighted avg       0.99      0.96      0.97      1018


4) Rest of Models

Accuracy: 0.75
Confusion Matrix:
[[759 251]
 [  2   6]]
Classification Report:
              precision    recall  f1-score   support

           1       1.00      0.75      0.86      1010
           2       0.02      0.75      0.05         8

    accuracy                           0.75      1018
   macro avg       0.51      0.75      0.45      1018
weighted avg       0.99      0.75      0.85      1018

Logisitc Regression
Accuracy: 0.58
Confusion Matrix:
[[532 392]
 [  2   6]]
Classification Report:
              precision    recall  f1-score   support

           1       1.00      0.58      0.73      924
           2       0.02      0.75      0.03        8

    accuracy                           0.58     932
   macro avg       0.51      0.66      0.38     932
weighted avg       0.99      0.58      0.72     932